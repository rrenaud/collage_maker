{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7019d9ac-b5b8-44af-b16e-e86fc76179df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrenaud/miniconda3/envs/collage2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rrenaud/miniconda3/envs/collage2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ipywidgets import widgets\n",
    "import PIL\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from improved_aesthetic_predictor import aesthetic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbedfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return torch.nn.functional.cosine_similarity(a, b)\n",
    "\n",
    "def shrink_image(img):\n",
    "    return img.resize((224, 224))\n",
    "\n",
    "def local_image_paths():\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                yield os.path.join(root, file)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85dd9fd-6e9f-43e3-9ea7-4178d2738fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aes_model = aesthetic_model.AestheticModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "637d5241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1040144]] (1, 768)\n"
     ]
    }
   ],
   "source": [
    "def sample_inference() -> aesthetic_model.AestheticInferenceResult:\n",
    "    img = PIL.Image.open(\"foobar.jpg\")\n",
    "    return aes_model.infer(img)\n",
    "    \n",
    "inference_result = sample_inference()\n",
    "print(inference_result.aesthetic_score, inference_result.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb423247",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(local_image_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all of the local images by computing their clip embeddings and aesthetic scores.\n",
    "# Write the outputs to a bunch of pickle files with the given BATCH_SIZE.\n",
    "\n",
    "filename_to_embedding = {}\n",
    "BATCH_SIZE = 128\n",
    "batch_no = 0\n",
    "def flush_batch(local_batch_no, embeddings):\n",
    "    fn = f\"aes_embeddings_scores_{local_batch_no}.pkl\"\n",
    "    print(f\"writing {len(embeddings)} outputs to {fn}\")\n",
    "    pickle.dump(embeddings, open(fn, \"wb\"))\n",
    "    embeddings.clear()\n",
    "\n",
    "\n",
    "for idx, image_path in enumerate(image_paths):\n",
    "    image = PIL.Image.open(image_path)\n",
    "    aes_inference = aes_model.infer(image)\n",
    "    \n",
    "    filename_to_embedding[image_path] = aes_inference\n",
    "    if len(filename_to_embedding) == BATCH_SIZE:\n",
    "        flush_batch(batch_no, filename_to_embedding)\n",
    "        batch_no += 1    \n",
    "\n",
    "if len(filename_to_embedding) > 0:\n",
    "    flush_batch(batch_no, filename_to_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5ef91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aes_embeddings_scores_pickles():\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    # Get the list of all embeddings files\n",
    "    embeddings_files = [fn for fn in os.listdir() if fn.startswith(\"aes_\") and fn.endswith(\".pkl\")]\n",
    "\n",
    "    # Load the embeddings from each file and add them to the dictionary\n",
    "    for embeddings_file in embeddings_files:\n",
    "        embeddings = pickle.load(open(embeddings_file, \"rb\"))\n",
    "        embeddings_dict.update(embeddings)\n",
    "    return embeddings_dict\n",
    "embeddings_scores = load_aes_embeddings_scores_pickles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a66c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_correlation(needle, haystack):\n",
    "    # Calculate the correlation between the needle and each row vector in the haystack\n",
    "    correlations = np.dot(haystack, needle)\n",
    "    \n",
    "    # Find the index of the row vector with the maximum correlation\n",
    "    max_index = np.argmax(correlations)\n",
    "    \n",
    "    # Return the maximum correlation and the corresponding row vector\n",
    "    return correlations[max_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af27701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "restricted_images_set = [v for v in embeddings_scores.items() \n",
    "                         # if not '202305' in v[0]\n",
    "] \n",
    "                         #   and max_correlation(v[1].embedding.squeeze(), accepted_images_embeddings) < .95]\n",
    "                         \n",
    "top_images_scores = list(heapq.nlargest(1500, restricted_images_set, key=lambda x: x[1].aesthetic_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dbe1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_images(images):\n",
    "    # Create a figure with a 4x4 grid\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "\n",
    "    # Iterate over the images and plot them in the grid\n",
    "    for i, image in enumerate(images):\n",
    "        # Shrink the image while preserving the aspect ratio\n",
    "        image.thumbnail((400, 400))\n",
    "\n",
    "        # Calculate the row and column indices in the grid\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "\n",
    "        # Plot the image in the corresponding grid cell\n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "981e4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8786796564403576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def diversity_score(M):\n",
    "    # Calculate the cosine distances between all pairs of vectors in M\n",
    "    distances = cosine_distances(M)\n",
    "\n",
    "    # Set the diagonal elements to infinity to exclude self-distances\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "\n",
    "    # Calculate the minimum distance for each vector\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    # Calculate the sum of the minimum distances\n",
    "    score = np.sum(min_distances)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Test case\n",
    "M = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, .5, .5]])\n",
    "result = diversity_score(M)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d436d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collage_quality(choosen_indexes, aes_inference_scores, diversity_over_quality_weight):\n",
    "    choosen_inferences = [aes_inference_scores[i] for i in choosen_indexes]\n",
    "    choosen_embeddings = [i.embedding.squeeze() for i in choosen_inferences]\n",
    "    diversity = diversity_score(np.array(choosen_embeddings))\n",
    "    quality = sum([i.aesthetic_score for i in choosen_inferences])\n",
    "    return diversity * diversity_over_quality_weight + quality * (1 - diversity_over_quality_weight)\n",
    "\n",
    "def find_best_collage(aes_inference_scores, num_images=16, diversity_over_quality_weight=.9):\n",
    "    best_indexes = list(range(0, num_images))\n",
    "    best_score = collage_quality(best_indexes, aes_inference_scores, diversity_over_quality_weight)\n",
    "\n",
    "    num_changes = 0\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "\n",
    "        for i in range(len(aes_inference_scores)):\n",
    "            for j in range(num_images):\n",
    "                this_collage = best_indexes.copy()\n",
    "                this_collage[j] = i\n",
    "\n",
    "                score = collage_quality(this_collage, aes_inference_scores, diversity_over_quality_weight)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_indexes = this_collage\n",
    "                    changed = True\n",
    "                    num_changes += 1\n",
    "                    print(f\"new best score {best_score} after {num_changes} changes\")\n",
    "        \n",
    "    return best_indexes\n",
    "\n",
    "best_indexes = find_best_collage([a[1] for a in top_images_scores], 16, .7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [top_images_scores[i][0] for i in best_indexes]\n",
    "collage = [PIL.Image.open(i) for i in image_paths]\n",
    "render_images(collage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
